---
title: "Ingest DSS TANF"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## LOAD LIBRARIES AND FUNCTIONS
```{r load_libraries, warning=FALSE, message=FALSE}
library(data.table)
library(dataplumbr)
library(here)
library(inspectdf)
library(maditr)
```

## DSS TANF Customers by Year
### Load data file
```{r cache=TRUE, message=FALSE}
dss_tanf_customers_by_year <- fread(here("data/original/q5/DSS/DSS TANF Customer by Year.csv"), colClasses = "character")
```

### Standardize column names
```{r}
colnames(dss_tanf_customers_by_year) <- name.standard_col_names(colnames(dss_tanf_customers_by_year))
```

### Check if more than one record per unique_id and calendar_year
```{r}
multiples <- nrow(dss_tanf_customers_by_year[, .N,.(unique_id, calendar_year_number)][N > 1])
multiples
```

### TANF records are actually Customer by Year by "Location", so multiple records per customer
if they received benefits in more than one fips code or zip code. As a single record is needed
per customer, additional columns must be created to account for all possible locations.
The number of columns added is based on the customer with the highest number of locations in a
single year.
```{r}
dss_tanf_customers_by_year[, county_fips_code_no := paste("county_fips_code", seq_len(.N), sep="_"), by=c("unique_id", "calendar_year_number")]
dss_tanf_customers_by_year[, zip_code_no := paste("zip_code", seq_len(.N), sep="_"), by=c("unique_id", "calendar_year_number")]
dss_tanf_fips <- dcast(dss_tanf_customers_by_year, unique_id + calendar_year_number ~ county_fips_code_no, value.var=c("county_fips_code"))
dss_tanf_zips <- dcast(dss_tanf_customers_by_year, unique_id + calendar_year_number ~ zip_code_no, value.var=c("zip_code"))
dss_tanf_customers_by_year_merged <- merge(dss_tanf_fips, dss_tanf_zips, by=c("unique_id", "calendar_year_number"))
```

### write to csv
```{r}
fwrite(dss_tanf_customers_by_year_merged, here("data/working/DSS/dss_tanf_customers_by_year.csv"))
```
